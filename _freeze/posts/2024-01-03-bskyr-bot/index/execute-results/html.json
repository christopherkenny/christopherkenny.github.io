{
  "hash": "191c1be794940f361e5155787adc2271",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Making a Scheduled Bot for Bluesky Social in R\"\ndate: \"2024-01-03\"\ndescription: |\n  Explaining the mechanics behind my CRAN Updates bot for Bluesky Social.\ncategories: [r-pkg, bskyr]\nimage: \"bsky profile.png\"\nimage-alt: \"The Bluesky profile for the CRAN Updates bot.\"\neditor: \n  markdown: \n    wrap: sentence\nknitr:\n  opts_chunk: \n    echo: false\n---\n\n\nThis post walks through how I set up a simple bot in Bluesky Social.\nThe bot, [@cranupdates.bsky.social](https://bsky.app/profile/cranupdates.bsky.social), posts every 2 hours with details about packages that have been updated, added, or removed from CRAN.\nEverything is run in R, primarily using the [bskyr](https://christophertkenny.com/bskyr/) package.\nIt's run for free on GitHub Actions and data is stored between runs using Google Sheets.\n\n![](bsky profile.png){fig-align=\"center\"}\n\nThe basic mechanics of the bot are:\n\n- fetch currently available packages with `available.packages()`\n- load the last run's data from Google Sheets\n- compare the two and identify changes\n- make posts with `bs_post()` for new packages, updated packages, and removed packages\n- save the current data to Google Sheets\n\nThis bot is entirely schedule based, so it doesn't need to interact with other Bluesky users.\nBelow, I detail how I set up the bot, including how to authenticate with Google Sheets (using [`googlesheets4`](https://googlesheets4.tidyverse.org/)) and GitHub Actions.\n\n\n# Setting up the bot\n\nTo set up the bot, we first need a public GitHub repo.^[You could use something more private, but for a generic bot, public means GitHub Actions is free and can get the job done.]\nFor my CRAN Update bot, I placed it in [`christopherkenny/bskyr-cran-bot`](https://github.com/christopherkenny/bskyr-cran-bot).\n\nNow, the basic file structure of the repo looks like:\n\n```\n.\n├── .github\n│   └── workflows\n│       └── post.yml\n├── bskyr-cran-bot.Rproj\n├── readme.md\n├── inst\n│   └── secret\n│       └── bskyr-cran-bot.json\n└── post.R\n```\n\nThe `.github` folder contains the workflow file, `post.yml`, which tells GitHub Actions what to do and is discussed in @sec-schedule.\nYou don't need a `bskyr-cran-bot.Rproj` or `readme.md` files, but they're nice to have.\nThe `inst` folder contains the `secret` folder, which contains the `bskyr-cran-bot.json` file, which is used to authenticate with Google and is discussed in @sec-auth.\nFinally, `post.R` is the script that does the work.\n\nFirst, let's explain `post.R`.\nI'm assuming that readers have some familiarity with R so will keep this brief.\nWith that in mind, first bit of code loads libraries and authenticates the user (here GitHub Actions):\n```r\nlibrary(bskyr)\n\n...\n\nauth <- bs_auth(bs_get_user(), bs_get_pass())\n```\n\n`bs_get_user()` and `bs_get_pass()` read from environmental variables.\nTo set these, go to the repo's \"Settings\" tab, then to \"Secrets and variables\" on the sidebar, and select \"Actions\".\nPress the big green \"New repository secret\" button.\nWe add two secrets:\n- `BLUESKY_APP_PASS`: the app password, created at <https://bsky.app/settings/app-passwords>\n- `BLUESKY_APP_USER`: your username\n\nA discussion of authentication for Google is available in {#sec-auth}.\n\nNext, we load the current data along with the last run's data from Google Sheets.\n\n```r\n# load available packages ----\npkgs <- available.packages(filters = c('CRAN', 'duplicates')) |>\n  as_tibble() |>\n  select(Package, Version)\n\n# Run first time to create a spreadsheet\n# gs4_auth()\n# gs4_create(name = 'bskyr-cran-bot', sheets = list(pkgs = pkgs))\n\n# get the old spreadsheet ----\nold_pkgs <- read_sheet(ss = '135p8xqI3LGIyuvwSjav13tY10fRu8dUPFjVNVal18Tk', sheet = 'pkgs')\n```\nBefore making the bot live, I first created the spreadsheet, using the commented out code.[^oops]\nThis simplifies reading the data and updating it later, but may not be necessary for all bots of this type.\n\n[^oops]: This created a small issue in the bot: Several of the first set of posts were about new packages that weren't actually new. This was because the first run of the bot was on a Windows laptop, while the second was on a Linux server. By default, `available.packages()` returns packages available for the current OS, hence the setting of `filters = c('CRAN', 'duplicates')`, which overwrites the default that filters to OS-available too.\n\nNext, we compare the two sets of data to identify changes.\n\n```r\n# identify changes ----\nupdates <- setdiff(pkgs, old_pkgs)\n\nnew_pkgs <- updates |>\n  filter(!Package %in% old_pkgs$Package)\n\nupdates <- updates |>\n  filter(!Package %in% new_pkgs$Package)\n\nremoved <- setdiff(old_pkgs, pkgs) |>\n  filter(!Package %in% pkgs$Package)\n```\n\nEach of these is then a `tibble` with 2 columns: `Package` and `Version`.\n- New packages are those which do not appear in the old data. These *could* have been archived before and may not be completely new.\n- Updated packages are those which appear in both data, but differ by version.\n- Removed packages are those which disappear in the new data, but were in the old dat.\n\nThen, we make posts for new, updated, and removed packages.\nTh processes for updated and removed packages are identical, so I'll go through posting about updates and new packages.\n\nFirst, for updating (and removed) packages, let's look at the whole snippet.\nThis is only run if there are updates (or removed packages), so it's wrapped in an `if` statement.\n\n```r\nif (nrow(updates) > 0) {\n  update_txt <- vapply(seq_len(nrow(updates)), function(i) {\n    paste0(updates$Package[i], ' (', updates$Version[i], ')')\n  }, character(1))\n\n  n_char_update <- cumsum(nchar(update_txt))\n\n  if (max(n_char_update) > 260) {\n    # split into multiple posts\n    update_txt <- update_txt |>\n      split(cut(n_char_update, breaks = ceiling(max(n_char_update) / 260))) |>\n      lapply(paste0, collapse = ', ')\n\n    lapply(update_txt, function(txt) {\n      bskyr::bs_post(\n        text = paste0('Updates on CRAN: ', txt),\n        auth = auth\n      )\n      # avoid immediate new posts\n      Sys.sleep(3)\n    })\n\n  } else {\n    update_txt <- update_txt |>\n      paste0(collapse = ', ')\n    bskyr::bs_post(\n      text = paste0('Updates on CRAN: ', update_txt),\n      auth = auth\n    )\n    # avoid immediate new posts\n    Sys.sleep(3)\n  }\n}\n\ncat('Updates:', nrow(updates), '\\n')\n```\n\nFor each pacakge update, we create a string with the package name and version.\n\n```r\nupdate_txt <- vapply(seq_len(nrow(updates)), function(i) {\n  paste0(updates$Package[i], ' (', updates$Version[i], ')')\n}, character(1))\n```\n\n\nThen, we calculate the cumulative number of characters in each string.\n```r\n  n_char_update <- cumsum(nchar(update_txt))\n```\nThis is important, as *posts are limited to 300 characters*. \n\nIf we only have to make one call, we can collapse the text into a single character entry.\n\n```r\nupdate_txt <- update_txt |>\n paste0(collapse = ', ')\n```\n\nThen we can just post it with one call to `bs_post()`\n\n```r\nbskyr::bs_post(\n  text = paste0('Updates on CRAN: ', update_txt),\n  auth = auth\n)\n```\nWe authenticated before, so we don't need to do it again, we just have to pass `auth = auth`.\nFor several posts in a session, this is better practice, as it avoids potentially dozens of extra calls to the API in a short period.\n\nIf it's longer, we can split it like so:\n\n```r\nupdate_txt <- update_txt |>\n  split(cut(n_char_update, breaks = ceiling(max(n_char_update) / 260))) |>\n  lapply(paste0, collapse = ', ')\n```\nThen we loop over the elements of `update_txt` and post them.\n\n```r\nlapply(update_txt, function(txt) {\n bskyr::bs_post(\n   text = paste0('Updates on CRAN: ', txt),\n   auth = auth\n )\n # avoid immediate new posts\n Sys.sleep(3)\n})\n```\nWe also add a short sleep between calls, of 3 seconds.\nThis isn't necessary, but is a simple way to avoid spamming the API.\n\nThe last line of this snippet prints the updates to the console, so that we can see what's happening.\n\n```r\ncat('Updates:', nrow(updates), '\\n')\n```\n\nThis makes it easier to debug, as statements printed will show up in GitHub Actions, like below:\n\n![](example_github_actions_output.png){fig-align=\"center\"}\n\nNext, let's look at the code for posting about new packages.\nThis is slightly different, as we want to post about each package individually.\nDue to limits on the size of package names on CRAN, we then also know that we don't need to check the character length of the post.\nFor the `i`-th new package, it runs the following:\n\n```r\nbskyr::bs_post(\n  text = paste0('New on CRAN: ', new_pkgs$Package[i], ' (', new_pkgs$Version[i], '). View at ',\n                'https://CRAN.R-project.org/package=', new_pkgs$Package[i]),\n  auth = auth\n)\n```\nThis creates a link to the new package (say NEWPACKAGE) as `https://CRAN.R-project.org/package=NEWPACKAGE` on CRAN.\n`bs_post()` will automatically process this and create linked text in the post.\n`bs_post()` can handle other inputs, including images and alt-text.\nSee the [package reference](https://christophertkenny.com/bskyr/reference/bs_post.html) for more details, including how to quote or reply to posts. \n\n:::{.callout-caution collapse=\"false\"}\n\n## Respectful Posting\n\nYou might note that the posts above don't contain any hashtags like `#rstats`.\nBluesky feeds are a bit different from Twitter and frequently are built by watching keywords.\nIf you are creating a bot that posts many times in a day, you may want to avoid using these in every post, as they can easily overwhlem these feeds.\nInstead, please use them sparingly, as anyone who wants to follow the bot can do so directly.\n\n:::\n\nBefore exiting, we want to update the spreadsheet, so that we can use it again in future runs.\nSince Google Sheets is our \"database\", we can just use `googlesheets4` to update it, just like how we read in the data.\n\n```r\n# update the spreadsheet ----\nwrite_sheet(pkgs, ss = '135p8xqI3LGIyuvwSjav13tY10fRu8dUPFjVNVal18Tk', sheet = 'pkgs')\n```\n\nThat handles the process of posting. \nBelow, I detail scheduling this script to run automatically.\n\n## Scheduling the run {#sec-schedule}\n\nTo schedule the run, we need to tell it a few things:\n\n- when to run it\n- what to run\n  - what environment variables it needs\n  - what R version to use\n  - what R packages to install\n  - what script to run\n  \nBelow, I explain these steps. But first, the completed workflow looks like:\n\n```yaml\non:\n  push:\n    branches: main\n  schedule:\n    - cron: '0 1,5,9,13,17,21 * * *'\n\nname: Post\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    env:\n      BLUESKY_APP_USER: ${{ secrets.BLUESKY_APP_USER }}\n      BLUESKY_APP_PASS: ${{ secrets.BLUESKY_APP_PASS }}\n      GARGLE_KEY: ${{ secrets.GARGLE_KEY }}\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: 'release'\n\n      - uses: r-lib/actions/setup-r-dependencies@v2\n        with:\n          packages:\n            any::here\n            any::dplyr\n            any::stringr\n            any::googlesheets4\n            any::bskyr\n\n      - run: Rscript 'post.R'\n```\n\nThis whole file lives in `.github/workflows/post.yml` in the [repo](https://github.com/christopherkenny/bskyr-cran-bot/blob/main/.github/workflows/post.yml).\n\nFirst, let's break down the when part:\n\n```yaml\non:\n  push:\n    branches: main\n  schedule:\n    - cron: '0 1,5,9,13,17,21 * * *'\n\n```\n\nThis tells GitHub Actions to run the workflow when there's a push to the `main` branch.\nIt also says to schedule the workflow to run every 4 hours.\nCRON entries are `minute hour day month weekday`, so `0 1,5,9,13,17,21 * * *` means to run at 1am, 5am, 9am, 1pm, 5pm, and 9pm every day.\nAs implied, setting the star says to run it every day, every month, and every weekday.\nMore documentation for the `schedule` part can be found [here](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule).\n\nThen we give the job a name, \"Post\", with `name: Post`.\n\nThe next section simply indicates we want the job to run on the latest version of Ubuntu:\n\n```yaml\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n```\nNext, we provide environment variables, that we set in the repo settings. \nSee {#sec-auth} for an explanation of the `env` GARGLE_KEY variable.\nThis step is like setting an .Rprofile file locally, but for GitHub Actions.\n\n```yaml\n    env:\n      BLUESKY_APP_USER: ${{ secrets.BLUESKY_APP_USER }}\n      BLUESKY_APP_PASS: ${{ secrets.BLUESKY_APP_PASS }}\n      GARGLE_KEY: ${{ secrets.GARGLE_KEY }}\n```\n\nNow, we can give it the steps to use. \n\n\nFirst, it needs to download the contents of the repo, so that it can access our `post.R` script.\n\n\n```yaml\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n```\n\nThen, we have to let it know to install R. \nWe can use one of the [`r-lib/actions`](https://github.com/r-lib/actions) actions, [`setup-r@v2`](https://github.com/r-lib/actions/tree/v2/setup-r).\nI'm using the released R version (4.3.2) at the time of writing this.\nYou could pin a specific version, but for bots, I plan to do the minor maintenance necessary as R versions increment.\n\n```yaml\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: 'release'\n```\n\nAnd then we list the packages we need. \nThis uses the [`setup-r-dependencies@v2`](https://github.com/r-lib/actions/tree/v2/setup-r-dependencies) action, again from [`r-lib/actions`](https://github.com/r-lib/actions).\nBelow, I make use of the  prefixes: `any::` and `github::`.\n`any::` is used for packages on CRAN, generally, but will also run if you've installed it elsewhere through a prior dependency.\n\n:::{.callout-tip collapse=\"false\"}\n\n## Using GitHub Packages\n\nYou can use `github::` in place of `any::` for packages on GitHub. \nYou just need to specify the user and repo.\nSo, if you want to use the dev version of a package, like `bskyr`, you could use the syntax:\n`github::christopherkenny/bskyr`.\n\n:::\n\n\n```yaml\n      - uses: r-lib/actions/setup-r-dependencies@v2\n        with:\n          packages:\n            any::here\n            any::dplyr\n            any::stringr\n            any::googlesheets4\n            any::bskyr\n\n```\nIf you already use `renv`, you could instead use that with the [`setup-renv`](https://github.com/r-lib/actions/tree/v2/setup-renv) action.\n\nFinally, we tell it to run `post.R` with:\n```yaml\n      - run: Rscript 'post.R'\n```\n\nThat's sufficient to tell GitHub Actions everything it needs to know to run the bot.\nBelow, I describe how to set up the authentication with Google Sheets.\nThis is only necessary if you're using it, like I am, to store data about the prior bot run.\n\n# Authenticating with Google for GitHub Actions {#sec-auth}\n\nTo authenticate with Google, we can use the [`gargle` R package](https://gargle.r-lib.org/index.html). \n`gargle` has a set of instructions for [Non-interactive auth](https://gargle.r-lib.org/articles/non-interactive-auth.html) and for [Managing tokens securely](https://gargle.r-lib.org/articles/managing-tokens-securely.html).\nThese provide a much more detailed explanation of the process, but I explain the important parts for our use case below.\n\nThere are four steps here:\n\n- Make a service account\n- Share the Google Sheet with the service account\n- Encrypt the service account key\n- Share details with GitHub to decrypt the key\n\n\n### Make a service account\n\nTo make a service account, we start at the [Google Cloud Console](https://console.cloud.google.com/).\nWe first need to make a project to hold the service account.\nWe can do this by clicking the project dropdown in the top left and clicking \"New Project\".\nThen, we can navigate to \"Service Accounts\" under \"IAM & Admin\" in the left sidebar.\nClick \"Create Service Account\" and give it a name.\nIt doesn't need any access to anything, so we can skip both \"Grand this service account access to project\" and \"Grant users access to this service account\".\n\nOnce we've created the service account, we can click on it in the list of service accounts.\nUnder keys, we can click \"Add Key\" and select \"Create new key\".\nSelect \"JSON\" as the type of key.\nThis downloads a file that we need for the next steps.\n\n\n### Share the Google Sheet with the service account\n\nThis may not really be a full step, but the first time I did this, I had no clue why it didn't work.\nWe have to give access to the Google Sheet from our new service account.\n\nUnder the service account dashboard on console.cloud.google.com, where we just were, we can view the email account that our new account uses.\nUnder the \"Details\" tab, there is an email, which will end with `.iam.gserviceaccount.com`.\nCopy this and open the Google Sheet.\n\nSimply share the Google Sheet with this email address, like you would any other email, and we're good to go.\nWhen we later encrypt the `.json` file from above, it will prompt us to allow any other access.\n\n### Encrypt the service account key\n\nNow, we need to encrypt the `.json` file we downloaded above.\nWe can use the [`secret_encrypt_json()`](https://gargle.r-lib.org/reference/gargle_secret.html) function from `gargle` to do this.\nFirst, we make our secret key to encrypt and decrypt with.\nWe can run:\n\n```r\nx <- gargle::secret_make_key()\nSys.setenv(GARGLE_KEY = x)\n```\n\nThis sets up the key in our environment, so we can use it in the next step.\n\nNow, we can run `secret_encrypt_json()` to encrypt the `.json` file.\n\n```r\nsecret_encrypt_json('path/to/downloaded/key.json', 'where/to/save/it.json', key = 'GARGLE_KEY')\n```\n\nFor consistency with where the key gets saved in packages, I used `inst/secret/bskyr-cran-bot.json` as the path to save it.\nThis file is encrpyted and needs to be pushed to GitHub.\n\nAt this point, we should take our script and run the first part locally to make sure the service account has proper permissions.\nWe can run:\n\n```r\nlibrary(googlesheets4)\ngs4_auth(path = gargle::secret_decrypt_json('inst/secret/bskyr-cran-bot.json', key = 'GARGLE_KEY'))\n```\n\nThis should prompt you to assign any permissions that it may need, primarily API access to Google Sheets.\nOnce you've run that, wait 3-5 minutes.\nThen, you can rerun the `gs4_auth()` line and it should work without any new prompts.\n\n\n### Share details with GitHub to decrypt the key\n\nNow that we know it works locally, we can share the details with GitHub.\n\nOpen the repo in a browser.\nGo to the \"Settings\" tab, then to \"Secrets and variables\" on the sidebar, and select \"Actions\".\nPress the big green \"New repository secret\" button.\nWe add one more secret:\n- `GARGLE_KEY`: the value returned by  `gargle::secret_make_key()` above, which should be the variable `x`\n\nFinally, we have to let the GitHub Action know where to find the key when it runs.\n\nIn the workflow file, we need to provide\n\n```\n env:\n   GARGLE_KEY: ${{ secrets.GARGLE_KEY }}\n```\n\nNow, for this, we also have two other environmental variables for the Bluesky authentication.\nSo it should look more like:\n\n```\nenv:\n   BLUESKY_APP_USER: ${{ secrets.BLUESKY_APP_USER }}\n   BLUESKY_APP_PASS: ${{ secrets.BLUESKY_APP_PASS }}\n   GARGLE_KEY: ${{ secrets.GARGLE_KEY }}\n```\n\n`gargle` discusses this more in the [Managing tokens securely](https://gargle.r-lib.org/articles/managing-tokens-securely.html#ci-configuration) article.\n\nWith that, the app should authenticate without problems.\nCombined with the script and workflow file, we have all the pieces to run the bot on GitHub Actions.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}